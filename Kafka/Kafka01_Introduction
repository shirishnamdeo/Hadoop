Apache Kafka

Ryan Plant




Linkedin:-
High Volume:
	-- 1.4 Trillion messages per day
	-- 175 terabytes data per day
	-- 650 terabytes of messages consumbed per day
	-- Over 433 million users


Kafka is a publish-subscribe messaging rethought as a Distributed Commit Log


What is Apache Kafka?
	-- A high throughput distributed messaging system.
	-- Apache Kafka is about getting large amounts of Data from one place to another.
	-- Rapidly, Scalaable and Reliably
	-- In computing terms, a term for transfering data is messaging. 
	-- Unlike other messaging systems, Apache Kafka is tailored for high through-put use cases, wehre vast 	amount of data need to be moved in Scalaable, Fault-Tolerant way.

	-- Application generates data like:-
		Logs, records in databases, key-value pairs, binary objects or messages etc.

	-- When businesses change, the variety of data increases, making the types of applications and the data-stores change as well.

	-- A lot of tools already exists to make this complex distribution topology possible. Most of there have been in technology tool-box for decades. 

Most common is database replication and Log shipping.
This is limited to certain kind of relational databases, that support Replication. 
The way database impletes replication is very specific to the database, and therfore doesn't work across vendors. 
So in a heterogeneous database environment, this becomes a limitation.


ETL - Extract, Transforma and Load
-- For integrating data between different sources and targets, ETL are implemented. 
-- Enterprise based ETL is very costly. 
-- Every ETL job that runs is a custom application, written by a developed who is specializes in ETL.




Messaging System establishes a fairly simple paradigm for moving data between Applications, Data Stores.
Traditional messaging system struggle with large scale implementations.

The means to collect and distribute data as messages relies on the role fo the messaging broker, which is ofter time the bottleneck.

-- Data Packte Size:- Larger messages puts severe strain on Message Brokers. This is a challenge as Broker cannot able to control messages coming from certain system. 

-- Also a messaging environmet is dependent on the ability for message consumers to actually consume at a reasonable rate. 

-- There is also a challenge of fault-tollerence. If a consumer pops something of the queue or reads it from a topic, its probably gone. So if the consumer loses a message or incorrectly process a message, it is extermly difficult to get it back to reporcess.



Peril of Messaging Under High Volume
Broker's jobs is to deliver or make available the messages to consuming applications, which consumes the messages at a reasonale rate. But under high volumes and variety of message sizes, the publisher can blast the BROKER with messages. 
If the application has not implemented some sort fo throttling, the broker can be put into a tough situation fast. 
Most messaging system are generally hosted on a single host, which generally relies on a limited amount of local or quoted storage. 
Generally, this isn;t a problem, as most messaging systems are usually very effieicnt, provided they can turn over the messages they are receiving fast enough before the storage becomes limited.  
But there is a problem when we have LAZY. SLOW or UN-RESPONSIVE consumer application.
In this case the Broker's disk can gets full, the broker croaks, become unresponsive, and now the publishing application can't publish thre messages.  

Another case is when there is a fault in the consuming application. Say due to a bug, the consumer processes a message incorrectly.
Broker can only keep the message for some time, not very long.



Multiple sources of data at different variety and velocities, 

Need for transfer of data:
	Cleanly -> Whihout a complex web of integration of different topologies
	Reliable -> To reduce the impact of any one component slowness or availability 
	Quickly  -> Real time use cases
	Autonomously -> Reducing the coupling between components so we can improve or change parts of the system without a cascading effect. 


Kafka:
	High Throughput
	Horizontally Scalaable
	Reliable and Durable
	Losely coupled Producers and Consumers -> One application rumtime conditions should not affect the others.
	Flexible publish-subscribe semantics -> Independent data producing application would send data on the topic, and any interested consuming application could lister in and receive data on that topic, which it can process and even publist again for others to consume.

As a CENTRAL BROKER of data, Kafka enable disparate applications and data stores to engage with one another with loosely coupled fashion by conveying data through messaging topics which KAFKA manages at scale and reliably. 




Kafka Architecture: _____________________________


Kafka is a messaging system. Specifically, its a publish-subscribe messaging system. 
A publisher creates some data and sends the data to a specific location, from where an interested and  authorizer subscriber can retrieve the messaging and process it.
 
Publisher -> Producers (Kafka)
Subsribers -> Consumers 

Producers and Consumers are simply the applications (the we write or use) that implement producing and consuming API's 

And the specific location to which the messages is sent to (in Kafka) is called TOPIC

Topics has names.
Topics can be initialized upfront or on demand.

As long as Producers and Consumers know the Topic Name and are authorized to send/recieve they can send and read messaged from a topic.


Messages and their TOPICs needs to kept somewhere, as Messages are PHYSICAL containeer of Data. 
BROKER is the place where Kafka keeps and Maintain its TOPICS. 
 
Broker is a software process, also refered to as a executable or deamon service, running on a machine (a server). 
The broker has the access to the resources on the Machine, such as FileSystem, which it uses to store messages which it categorizes as TOPICS.
It is in the Kafka broker, where the differences between other messaging system becomes apparent.


How the Kafka Broker handles messages and their topic, is what gives Kafka its high throughput capabilities.
Acthiving high throughput is a function of how well a system can distribute its load and efficiently process it on multiple nodes in parallel.

With Apache Kafka, you can scale out the number of Broker as much as needed to achieve the levels of throughput required, and all of this without affecting existing Producers and Consumers applications.

Linkedin > 1400 Brokers, processing 2 Patabytes per week.



A Kafka cluster is grouping of multiple Kafka Brokers. You can have single broker or multiple brokers on a single machine or on multiple machines.

Cluster Size -> No of Brokers.
Kafka cluster is thw grouping of Brokers. It doesn't matter if they are running on same or multiple machnes (as fas the cluster terminology is concerned)


Distribute System -> Is a collection of resources that are instructed to achieve a specific goal or function.
It consists of multiple workers/nodes.
The system of nodes requires co-ordination to ensure consistency and progress towards a common goal. 

Co-ordination avoids duplication of effort or individual worker nodes, undermining each other's work without knowing it. 

In Kafka, these workers nodes are the Kafka brokers. 


Within the distributed system, there is a hierarchy, that starts with a controlled or a supervisor. 
A controlled is just a worker node like any other. It just happened to be elected from amongst its peers to officiate in the administrative capacty of a controller.
In fact, the worker node selected as the controller, is commonly the one thats been around the longest, plus other factors.

Critical responsibilities of Controller:-
	-- Maintain the inventory of what workers are available to take on work. -> Attendence
	-- Maintain a list of work items that has been commited to ans assigned to workers. -> Work Items
	-- Maintain active status of Staff/Workers and their progress on assigned tasks.


In Kafka:-
	Controller + Workers -> Cluster
	Workers/Members -> Brokers

When a taskes comes in, say from a Producer, the controller has to make an decision which worked should take that task. 
For this the ontroller needs to know who is available and is in good health, and very IMPORTANTLY what risk policy should govern its assignment decision.

Risk Policy -> Like Redundancy Level. (What replication to employ in case an assigned worker failes.)
Work already done should not be Lost.
This means each task given to a worker must also be given to a worker peer.

For a assignment, if the controller determines that redundancy is required, it will promote a worker into a LEADER, which will take direct ownership of the task assigned. 
Say if 3 replicas neeed, then it will be the Leader's job to recruit tow of its peers to take part in replication. 

In Kafka, the RISK POLICY to protect against the loss is known as the REPLICATION FACTOR. 

Once peers have commited to the leader, a QUORUM is formed, and these commited peers take on a new role in relation to a leader, a FOLLOWER.

If for some reason a Leader cannot get a QUORUM, the controller will reassign tasks to the Leaders that can. 


In Kafka, the work that the Workers or Brokers performs is RECEIVING messages, CATEGORIZING them into topics, and RELIABLE persisting them for eventual retrieval. 

Conparitively speaking, the efforts required to handle messages from the producers is substantially less then the effort required while handle messages to give it to consumers. 



Every component within a distributed system has to keep some form of communication going between themselves. 
This Communication refered to as Consensus/Gossip protocol.
Like, events releated to Brokers make available and requesting Cluster Membership, or Broker Name loopup, retrieving bootstrap configuration settings, and notify new settings.
Events like Controller and Leader election, Health status updates like heart beat events. 

Apache Zookeeper
Used in variety of distributed sysems for all the reasons mentioned above.
	-- Zookeeper servers as a centralized service for metadata about vast clusters of distributed ndoes.
	-- Configuration Information
	-- Health status
	-- Cluster synchronization status 
	-- Cluster and Quorum group membership, including roles of elected nodes.
	-- Systems like Hadoop, Hbase, Mesos, Solr, Redis, Neo4j depends on Zookeeper.
	-- Zookeeper itself is a distributed system, and for it to run reliably, has to have multiple nodes which form what is called an 'Zookeeper Ensemble'

Zookeeper provides the brokers (I believe broker's information instead) within a clusters to Kafka, and the Metadata about the cluster. 
As this Metadata is constantly changing, connectivity and chatter between the zookeeper and the cluster members is required. 

Netflix:
4000+ Brokers, 36 clusters, 700 billion messages per day.





Topics, Partitions, Brokers: ____________________

Kafka Installation
	-- Linux Recommended
	-- Java 8 JDK
	-- Scala Installed 2.11.x + (Kafka written in Scala)

Note that the Kafka and Scala must be compatible, so check their version compatibility.

Kafka installation itself have zookeeper jar, which means Kafka installation is self-contained, not require zookeeper to be installed prior and separately. 

conf/server.properties -> Is the configuration file for the Kafka Brokers itself.
bin/windows -> for Windows .bat files.



Kafka Topics:
	-- Primary abstraction of Kafka 
	-- Kafka Topics are essentially just the named feed or category of messages. Its an addressable, referencable collection point for messages that producers sed messages to consumers retrieve messages from.

	-- Kafka Topic stores the messages as time-ordered sequence of messages, that share the same category.

	-- Topics is a LOGICAL entiry, and it VIRTUALLY span across entire cluster of Brokers, for the benifit of Scalability and Fault-Tolerence.
	-- Producers and Controller don't really know or care about how the messages are kept, they just care about the Topic to work with. Producers just need to publish messages on the topic. How Topic is managed inside the Cluster of Brokers is not its convern.

	-- Behind the scenes, for each TOPIC, the KAFKA cluster is maintaining one or more PHYSICAL LOG files.


When a producer send a message(events) to a Topic, the messages are appended to a time-ordered sequential stream.
Each messages are Immutable. Once they are received into a topic, thay cannot be changed.
Somehow, if the producer sends the message which is incorrect or represents a fact that is no longer valid, its only recoruse is to follow up that previous messages with a newer more correct one. 
It is the job of the consumer to reads them and processes them.


This style of maintaining data as events is an architectural style knows as Event Sourcing.


A KAFKA Message has:-
	Timestamp -> Is set when a message is received by a Kafka Broker.
	Unique Identifier -> Referenceable identifier.
	Binary payload of data

	--Combination of Timestamp and Identifier form its placement in the sequence of messages received within a Topic.
	The identifier itself is referencable by the consumers in order for them to operate autonomously and effeciently. 

	-- Kafka's one of the design goal was to theoritically make the message consumption possible for the message to be consumed by unlimited number of independent and autonomous Consumers.

	-- There may be many consumers that are interested in receiving message at the same of different time. Furthermore, if a consumer errorneously process some messages, that fault should not have any impact o an other consumer or producer. Each should maintain its own operational boundary from one another. 


Message offset:-
	-- Helps consumer to read messages at their own pace and process them independently.

	-- Offset
		A placeholder, Last read message position. 
		Offset is entirely established and maintained message consumer (Consumer maintains what it has read and what it has not read.)
		Offset itself refers to the Message Identifier (described above).

When a consumer wishes to read from a topic, it must establish a connection with a Broker. The consumer decides what messages it wants to consume.
If the consumers has not read from the topic, or if had read, but again wants to read from the beginning of the topic, it will issue an statement to read from the beginning of the Topic. 

Behind the scene, it is essentially establishing that its message offset for the topic is 0. And as its reads messages, it will move its offset accordingly.

A consumer can choose to advance its position, stand on the offset, or go back to RE-READ another previously read messages, all without the producer, broker or other consumers know or care.

When new message arrives, the CONNECTED consumers will receive an event indicating that there is a new message and consumers can read and advance its possition.

When the last message in the Topic is read and processed, the consumer can set its offsetm and at that point is caught up.


Kafka is IMMUNE to SLOW Consumers -> Becuase it has the means to retain messages over a long period of time. 
Time it can retain messages is configurable and is known as Message RETENTION POLICY. (in HOURS) 
Default -> 168 Hours (7 Days)

Retention period is defined on per Topic basis.

All messages are retains by the Kafka, regadless if a single consumer has consumed a message.





To run kafka, atleast Zookeeper and one Broker is essnetial.

zookeeper-server-start.sh -> need a configuration file to know how zookeeper should behave once started.
Once zookeeper is started, it will wait for processes to connect to it.

bin/zookeeper-server-start.sh config/zookeeper.properties



telnet localhost 2181 -> To test zookeeper environment is running, and issue a zookeeper four-letter command, such as 'stat'

standalone -> mode of zookeeper means there is only a single instance of zookeeper running. (For Development and testing purposes)


bin/kafka-server-start.sh config/server.properties
-> It will start and register Broker with the zookeeper server and is available to work.


bin/kafka-topics.sh  

bin/kafka-topics.sh --create --topic my_topic --zookeeper localhost:2181 --replication-factor 1 --partition 1

	-- need to pass in zookeeper server, because there can be multiple zookeeper instances, each of them managing their own independentl cluster. By specifying the zookeeper here, we are essentially saying that I wanted to create a topic on this zookeeper managed cluster. 
	It is Zookeeper component that is responsible for assigning a broker to be responsible for the TOPIC.

	Q. Then, how are nodes differe from Broker? 

Zookeeper scanned its registry of Brokers and made a decision to assign a broker as the Leader of the topic. 
Senondly, on the broker, there is a logs directory, and in there a new directory is created, with the topic name and suffix.
Within this directory, there are 2 files.
	index files
	log file -> Contains binary format


Enquire about the topics avaibales on the cluster
	bin/kafka-topics.sh --list --zookeeper localhost:2181


producer:
bin/kafka-console-producer.sh --borker-list localhost:9092 --topic my_topic

Every message we type will cause the producer to sent the message to the Broker, which will then COMMIT it to its log, waiting for a consumer to consume them.


consume:
bin/kafka-console-consumer.sh --borker-list localhost:9092 --topic my_topic  --from-beginning



Kafka architecture was built on COMMIT LOG
	Source of Truth
	Physically sotred and Maintained
	Higher -order data structires derive from the Log
	Logs are the point of recovery, ex transactional log in Traditional Database
	Log are the basis of replication and distribution to occur for redundancy, fault-tollerence and scalability

Kafka is a publish-subscribe messaging rethought as a Distributed Commit Log.
Kafka is essentially a highly distributed Raw database (analogy from Traditional Database commit log), that brokers read and writes. 



Kafka Partitions:
Topic (a logical concept), is represented by on or more PHYSICAL LOG files called PARTITIONS.
No of partitions in a topic depends on circumstances in which Kafka is intended to be used.
No of partitions -> Configurable 

Partition is the basis for which Kafka can achieve its ability to:
	Scale out
	Fault-Tolerent
	High-Throughput

Each partitions is maintained on atleast one or more Brokers.
Each topic at minimum has to have a single PARTITION, as it the physical representation of the topic as a commit log stored on one or more brokers.

Log on Broker filesystem, /tmp/kafka-logs

/tmp/kafka-logs/{topic}-{partition}

Physical Resources: CPU, Memory, Disk-Space, Netowork 

Each PARTITION must fit entirely on ONE MACHINE. A single partition on multiple machines CANNOT be splitted.

So if we have only one partition for a lagre and growing Topic, we will be limited by one broker node's ability to capture and retain messages being published to that topic. 



In general, the scalability of Kafka is determined by the number of PARTITIONS being managed by muliple broker nodes.

--partitions 3
Suppose if 3 partitions is used for a topic, this means that the single topic to be split across three different log files, ideally managed by three different broker nodes. 

Each partition is mutually exclusive from one-another, in that they recieve unique messages from a kafka producer producing messages on the same topic. 
This enables each partition to share the burden of message load across multiple different broker node, and increase parallelism of certain operations, like message consumption.

Kafka producer splits the messages across different partitions -> Based on partitioning scheme that can be established by the producer.
Partitioning scheme is important to make the partition balanced for a topic.


Q. *** Is there is distinguished KAFKA-Producer installed on the producer machine which takes care of the partitions?



This is how partitions get distributed to the available brokers in the cluster.
When a command to create a topic, with say, 3 partitions is issued, it is handeled by zookeeper., who is maintaining metadata regarding the cluster.

Now, the zookeeper is specifically going to look at the available borkers and decide which brokers will be made responsible leaders for managing a single partition within a topic. 

When this assignment is made, each unique Kafka broker will create a log partition directory for a newly assigned partition.
(I believe additionally, the leaders will assing the peers for replication, as per replication policy)
 

Additionally, as partition assignments are broadcast, each individual broker maintains a subset of metadata that zookeeper does, particularly the mapping of what partitions are managed by what brokers in the cluster.

This enables any individual broker to direct the producer client to the appropriate broker for storing messages to a specific partition.

Along the way, status is being sent by each borker to Zookeeper, so that a proper consensus can be maintained in the cluster. 

When a procucer is ready to published messages to a a Topic, it must have knowledge of atleast one broker (just any brokers, or only brokers among the leaders of that topic?), so it can find the leaders of the topic-partition. 
Q. *** How producer at the very first get acces to any broker in the cluster?


Each broker knows which partitions are owned by which leader. 
The metadata related to the topic is sent back to the producer so it can begin to send messages to the individual brokers participating in managing the topic-partition. 


Consumers, operates much the same as producer does, but levarage Zookeeper a bit more.
When consumer, consuming message from the cluster, the consumer inquires Zookeeper about which broker owns which partitions, and gets additional metadata that affects the consumer's consumption behaviour, particularly in the scenarion when there are large groups of consumer sharing the consumption workload. 


Once the consumer knows about the borkers, with the partitions that makeup the topic, it will pull the messages from the brokers based on the message OFFSET per partition. 

Beacuse messages are produced at multiple partitions, and pottentially at different times, consumers working with multiple partitions are likely to consume messages in different orders, and will therefore will responsible to handling the order (if required).


More partitions increases the degree of parallelism in which consumers can consume those messages. 



Partitions Trade-Off
	The more partitions there are, the more entries zookeeper has to make to keep track of them, and since Zookeeper works on this resigtry in memory, the recources on zookeeper can become constrained. 
	Though this can be mitigate by ensuring Zookeeper ensemble is properly provisioned, for the growth of topics and their partitions. 

	Every message in each partition is totally orderd, in the sequence in which it is received. But as topic can has multiple partitions, thus there may not be a global order to messages in a topic across all the partitions.
	This can be complex if the consuming application needs to have a Global Messaging order in the topic across all partitions. To get a global order wthout the consumer having to manage the ordering process, you may need to consider a SINGLE partition for a topic. -> Limited in terms of scalability as now there will be a single broker managing that topic single partition.

	Alternativelt, we can intellengently use consumer or consumer groups to consume messages from the topic-partitions and handling the ordering process there. 

	Also when we have higher number of partitions, the process of leader falling over to another can start to get time consuming. The fail-over process happens very fast, in low mini-seconds, but in large cluster with large number of partitions, this can start to add up. 
	Which is why in big-big implemenations, we will see multiples clusters on their own. 



Faults like:
	What is the broker fails and become unresponsive?
	What if there is a Netowork Issue which make broker unreachable?
	What is the disk on the broker fails and data is inaccessible?


When a broker is down, its the responsibility of the Zookeeper when it determines that a broker is down, to find another broker to take its place. And the metadata used for work distribution for either producer or consumers will get updated and the system will go on. 

Redundancy of data is kept, so the the data kept by the failed broker is NOT Lost. -> Configurable. 
--replication-factor N (N=1 means only one data)


Replication Factors
	-- Reliable work/data distribution. 
	-- Makes cluster resilience 
	-- Fault-Tolerent

	-- With replication-factor = N, N-1 broker failure tolerance. 

	-- replication-factor can be set per Topic basis.

Wnen replication is more than one, it is the Leader's job to get the peer brokers to participate in the Quorum for the purpose of replicatig the log to achive the intended redundancy level. 
When the leader has the Quorum, it will engage its peers to start copying the partition log. 

When all the members of the replicatig Quorum are caught up, and a full synchronzed replica set is in place, it is reported throughout the cluster that the number of IN-SYNC-REPLICAS (ISR), is equal to the replication factor for that topic in each partition within it. -> Important Metric.

When ISR == Replication Factor, -> Topic + Topic-Partitons is considered to be in health state. 

If for any reason a Quorum cannot be established, and/or the number of ISR fall bwlow the replication-factor for that topic, intervention is required. 



There might be reasons, a broker may not be able to replicate. And because of that Kafka doesn't automaically go out and search for a new following peer to replace the Quorum member.
Q ** Why Kafka don't do this? -- I believe it does.


Despite how resilient kafka is, vigilant monitoring and compensating actions are eneeded to eventually replace or tune a lagging or missing in action member of the Quorum. 




Demo
Creating multiple brokers
Need to create a separate server.properties file for eacg borker we want to instantiate.
ex.
	server-1.properties
	server-2.properties
	server-3.properties

Also when we have multiple brokers, when instantiating a producer, we need to pass the --broker-list parameter
--borker-list localhost:9092 

On Broker faliure, as an administrator when we see that there are less ISR than a replication-factor, then this tell there is a missing replica, Quorum is unhealthy and it needs to be replaced. 

If there is another broker avaibale, Kafka woudl have already added that to the Quorum ans start replicating it. 









Producing Messages with Kafka Producers: ________

Write applications to publish messages to Kafka.
Some important configuration properties tha affect the messages sending behaviour.

Developing Environmet Setup
	Adding Kafka Client Libraries
	Java 8 JDK
	Maven 3
	Access to test Kafka Clusret (Atleast one running Kafka Broker)


Kafka Client need an object to represents the required configuration properties needed to start up a producer. 
3 required properties needed:-
	bootstrap.servers 
		-- Needed for the server to start-up.
		-- Procuder doesn't connect to every broker referenced in the list, just the first available one. 
		-- It uses the broker it connects to, to discover the full membership of the cluster.
		-- Procuder user this list to determines the partition owners or leaders so that when it is ready to send messages, it can do so immediately. 
		-- It is best practice to provide more than one broker in the proker list.  


	key.serializer
	value.serializer
		-- Message content is binary encoded. To optimize the size for storage, network transistion and compression. 
		-- Since, it the producer that serves as the beginning of the message life-cycle, it is responsible for describing how the message content are to be encoded so that the consumer can know how to decode them.  


Configuration items are key-value pairs. Dictionary to hold this is createed using Properties() class. 


KafkaProducer -> Is the Primary class, that makes the generic console applicaion an actual Kafka Procuder applicaion. 


Inside the implemnetation fo Kafka Procuder, notice a type called ProducerConfig. 
When a Kafka Procuder object is created, the properties are used to instantiate an instance of the ProcuderConfig class, and from there, all producer configuration is defined and referenced internally. 
It is from this object, that the internal field for key and value serializer are initialized. 


From the point of view of Kafka producer, it doesn't really send messages. 
No type in a entire Kafka API called message, infact a class calles -> ProducerRecord, and it will represent what will be pubmish by Kafka producer.

ProcuderRecord only required two values to be set in order for it to be considered a valid record that can be sent by a Kafka Procuder.
	Topic
	Value -> The message content
Other optional values
	Partition -> 
	Timestamp -> Explicit setting of the timestamp to the producer record.
		Timestamp is transmitted with the message. Long data type -> Additional overhead 8 Byte of payload. 
		This overhead can affect the performance and throughput in high volume situations.

		-- Actual timestamp that will be logged for a message will be based on setting defined in the broker's server.properties
		log.message.timestamp.type = [CreateTime, LogAppendTime]
	
	Key -> Is a value that if present will determine how and to which partition within a topic the Kafka producer will be sending message to.
	It can strongly influence the manner in which messages are routed to partitions.




In the shell program, Serializer is hard-coded to use the String Serializer.

If we were to try and create a producer record, that didn't match the serializer type specification for the producer, the producer would generate a runtime serialization expection. 




Message sending process in two parts (Looking in to how message is sent and what happens internally)

When calling the send method, the producer will reach out to cluster using the bootstrap servers list to dscover the cluster membership. 
The response comes back as a metadata, containing detailed infromation related to the topics, their partitions, and their managing brokers on the cluster. 
This metadata is used to instantiate a metadata object in the producer, and throughout the producer's lifecycle, it will keep this object fresh with the latest information about the cluster.
Additionally, a pseudo processing pipeling within the kafka producer is engaged.
With the producer now having an actual producer record to work with, the first step in this pipeline will be to pass the message through the serializer using the configured serializer.

The next step in the pipeline is the partitioner, whose job is to determine what partition to send the record to.
Here the producer can employ different partitioning strategies depending on the values being passed to it in the producer record, and the information it has regarding the cluster membership.


Between the time the send operaton is invoked to the time a message is recieved by a Broker, quite a few things happen.
Partition step is determined by four possible strategies.
First, the Kafka producer looks at the ProcuderRecord contents, especially the partition field. It will look if there is a value provided for that partition field. If it has, the next question will be if the proposed partition is actually a valid partition.

The producer refers to the metadata object for this answer, which maintains the cluster metadata.
If the proposed partition does not match a known partition for the topic, or if the partition is unavailable, which is unlikely if the replication is enabled, an Expection will be thrown, and the send operation will be abort.

If the proposed partition is valid, then the producer will add the producer record object to the specific partition buffer for the topic where it will, on a seperate thread, await the actual send to the broker leader of that specified partition.



No Partition + No Key -> Round Robin Strategy, that attempts to evenly distribute the messages across all the partitions. 

See Visual **





Sending the Message Part 2



With the partitioning scheme established, producer can now dispatch the producer record onto an in-memory queue like data structure, called RecordAccumulator.
RecordAccumulator is a fairlt low level obejct that has a lot of complexity. 

Micro-Batching
Whether it be on producing side, the broker side or consumer side, Kafka is designed with the means of being able to rapidly queue or batch up requests to send, presist or read in flexible bound memory buffers that can take advantage of modern day operating system functions, such as Page-Cache, and the Linux sendfile() system call. 

By batching, the cost overhead of transmission, flushing to disk, or doing a network fetch is amortized over the entire batch. 
The RecordAccumulator gives the producer its ability to micro-batch records intended to be sent at high volumes and high frequencies. 

When a ProcuderRecord has been assined to a partition through the partitioner, it will get handed over to a RecordAccumulator, where it will be added to a collection of RecordBatch objects to each topic partition combination needed by the producer instance. 

Each of these RecordBatch objects, is a small batch of records that is going to be sent to the broker that owns the assigned partition. 


batch.size -> Max Bytes per each RecordBatch.
buffer.memory -> Max Memory in Bytes threshold. 
max.block.ms -> For how many mimiseconds, the send() method will be blocked for.
				This will put pressure on the thread of the producer to send more messages onto the buffer.
				Hope is that within the provided number of miliseconds the recors will be transmitted, to free up more buffer memory. 

linger.ms



Delievery Gurantees
When sending the message, the producer can specific what level of acknowledgement it expects from the receiving boker. (acks)
	0 :- Fire and Forget (no acknowledgement is snet by broker), okay for messages like click stream data
	1 :- Producer onl asking for Leader broker to confirm receipt and persistence, instead of all replica member of the Quorum.
	2 :- Requesting from all In-Sycn-Replica (performance cost)



Ordering Guarantees
Message order is only preserved within a given partition. If the producer send messages to a partition in a specific order, that order will be the order in which the broker appends them to the log, and it will the order that the consumer will read them from the log. 
Messages sent to multiple partition will not have a Global Order.
 
max.in.flight.request.per.connection => 1
Which will effectively tell the producer that at any given time only one request can be made. 




We shoudl always gracefully close down the procucer. If not done, this can cayse memory leaks.




Consuming Messages with Kafka Consumers and Consumers Groups: _____________________________________

In consumer, as we are receiving messages, we need to use de-serializer.
This must correspond to the type specification of the producer message that was serialized with the same serializer class. 


Producers publish the messages, while the consumers subscribe to.

subscribe()
The method signature for subscribe takes in a collection of string, which represents a list of topics. 
A single consumer can subscribe to any number of topics.

Calls to subscribe are NOT incremental, meaning that any subsequent call to subscribe will overwrite wahtever it had in there before.
Best approach is to maintain the topics of interest into a separate structure, managed it there ans pass in a reference to the topic list. 


Unsubscribe()
	-- This means Unsubscribe from all topis.


subscribe()
	By calling this methods we are asking for automatic or dynamic partition assignment.
	That is to say that you are enlisting the single consumer instance to evntually pull from every partition within that topic. (can atleast one by can be many partitions too)


assign()
	Subscribing to individual partitions.
	The assign method is only valid for subscribing to a list containing the class 

	One or more partitions, regardless of topic

	By asking for a specific partitons, you are basically taking on the responsibility of assigning yourself specific partitions.
	Assigning specific partitions to a single consumer instance.

	Once you have assigned yourself to specifics partitions, the consumer will then start pulling the individual partitions, regardless of the topic of those partitions.

	Cannot be added incremental as subscribe()

	Helps when the consumer want complete control over the partitions it wants to pull messages from.




How Kafka consumers interact with their subscribe topic.

When a single consumer subscribe to a topic using the subscribe() method, it will constantly pull any and all the partitions withing the topic for new messages to consume.
This is the case for all of the topics to which the consumeer has subscribed.

The benifit of using the subscribe methods to retrieve data is that partition management is entirely managed for you. 
Ex. If an new partition is added to an existing topic, presumable because the administrator wanted to increase the scalability of the topic.

When that happens the METADATA about the cluster will have changed, and it will be sent to the consumer.

Since the consumer maintains an internal object that manages its subscriptions called subscription state, it will know if the change has affected its subscriptions. 
If it does, so the new partition will be automitically added to the topic list, which the consmer will start POLLING for messages. 

This capability one available in subscribe() method.



With assign(), if a partiton is added to a topic, the consumer instance may be notified of it as per the protocol of retrieving metadata from the cluster, but it doesn;t relly care, as this consumer has itself wanted to subscribe to a certain paritions only.






The Poll Loop
By invoking just the subscribe() or assign() methods, consumer WON'T start recieving messages.
The Poll Loop is the heart and soul of the Kafka Consumer, and it is what enable the consumer to realize its purposem and that is to continuously and reliable poll the brokers and the cluster for messages.

Its a methods from which all the interactions between the consumer and the broker are kicked off and co-ordinated. 


A Kafka consumer is a, and should be a long running application, whose job is to always be looking for new nesages and process them.

poll(T) method returns an object of ConsumerRecords, which contains any records the consumer was able to retrieve from the broker. 
T -> is the timeout value





Demo Consumer


Messages are generated by the producer perf test tool.
bin/kafka-producer-perf-test.sh
This tool is to verify the producer performance.



Consumer Polling 

When the subscribe() and assign() methods are invoked, the content of the collections they were passed to are used to set fields withing the subscription state object.

This objects servers as the source of truth for any and all details related to the topics and partitions this consumer instance is subscribed or assigned to.

A lot of what happens within the consumer invariably corsses paths with this object. 
This object also plays a very important role with the consumer co-ordinator in managing the offses.

When poll() is invoked, consumer settings, particularly those referring to the bootstrap servers is used to request the metadata about the cluster.
This kicks off everything within the consumer.

The Fetcher serves as the responsible object for most of the communication between the consumer and the cluster.
Within it, there are several fetch related operations that are executated to initiate communication with the cluster, but the Fetcher itself doesn't actually itself communicate with the cluster, taht is the job of the Consumer Network Client.

With the client open and sending TCP packets, the consumer starts sending heart-beats, which enable the cluster o know what consumers are still connected.

Additionally, the initial request for the metadata is sent and received.
The response is used to instantiate its internal metadata object, which will keep up to date while the poll method runs, getting periodic updates from the cluster, when cluster details change.

With metadata available, other major components become more involved.

With information about the cluster, the ConsumerCoordinator can now take responsibility to co-ordinate between the consumer. 

This object has two main duties.
	1. Being aware of automatic or dynamic partition re-assignment, and notification of assignment changes to the subscription state object.
	2. For commiting offset to the cluster, the confirmation fo which will cause the update of the subscription state, so it that is can always be aware be the status of topics and partitions.

To actually start retrieving messages, the Fetcher needs to know what topics or individual partitons is should be asking for.
Its gets this information from the subscription state object, and with it start requesting messages. 

Poll timeout value, is a setting representating the number of miliseconds the network client is to spend polling the cluster for messagess before returning.
It establishes the minimum amount of time each message retrieval cycle will take. 

When the timeout expires, a batch of records are retuenrd, and added to an in-memory buffer where they are PASRED, DE-SERIALIZED, and GROUPED into consumer records by topics and partitions.

Once the fetcher finishes this process, it returns the objects for processing.




The poll() process is a single-threaded operation.
That is Kafka Consumers are essentially single threaded. There is one poll loop per Kafka consumer, and you can only have single thread per Kafka consumer.
Kafka consumer is designed this way mainly to keep the operations simple and to force parallelism of message consumption in another more scalable way.



After the poll method returns the messages for processing, since the return type of the poll method is a collection of ConsumerRecords, we will need to iterate through them to process them individually.



How Kafka manages offsets is very important to understand.

Offset - the last read position the consumer has read from a partition within a topic.

Different categories of offset, with each representating the various stage they are in.
When an individual is reading from a partition, it obviously needs to establish what it has read and hasn't read. This difinitive answer is called the last commited offset, and it represents the last record the consumer has confirmed to have processed.

This is the starting point for a consumer withing any given partition, depending on the configured offset reset behaviour/policy.

Each partition is mutually exclusive with regard to consumer offsets. 
So for any given topic, a consumer could have multiple offsets it is tracking, one for each partition within a topic.
As the consumer reads records from the last commited offset, it tracks its current possition. This offset position advances as the consumer advances in the log towards the last records in the partition.

Last reocrd's offset is known as log-end-offset.

The difference between the current position and the last commited offset, is pottentially uncommitted offsets.

The success of robust and scalable message consumption in Kafka, largely depends on your understanding of what creates this gap and what can be done to narrow it. *** IP


There are two very important configurational properties that govern the default behaviour of the consumer offset. These properties are optional because dafaults are sufficient for getting up and running.
1. enable.auto.commit -> Giving Kafka the responsibility to manage when current position offsets are upgraded to full committed offsets. 
This is a fairly blind setting because Kafka isn't going to know under what logical circumsances a record should be considered a commited record.
The only thing it can do is establish an interval of time between commit actions, that faithfully commit based on a frequency.
This frequency is establish by auto.commit.intercal property, by default to 5000 milisecond (5 second).


But there is a problem. 
Let see a scenerio, that a record is in processing scope with the currect offset value -> 4, because the last successfully commited record was 3.
Let's also suppose that for whatever reason, the processing of the current record takes linges than 5000ms (or whatever that interval is set to). 
Faithfully, Kafka is going to commit that record offset, regardless if it is finish processing or not. This is not consistent. !!!! 



The gap between waht is CONSIDERED commited and what actually commited isn't entirely bad. Many large scale distributed systems are not 100% consistent. They are EVENTUALLY consistent, and Kafka consumer don't have to an exception to that.
But the extext in which you can tolerate eventually consistency is based on your applications functional requirements ofcourse, but also on the degree in which you can ensure reliability.



So suppose an error occur that causes the message processin got fail for whaever reason.
Depeding on how far behind he consumer was when it fail, it may be very hard to know where you need to go back to, to start processing again, because according to Kafka the records were commited. 



Just because somethig is read, doesn't mean it is commited. -> Policy Depends on offset management mode we are operating in.
The offset management mode is determing by the offset configuration propeties.
1. 	Whether you want Kafka to manage your commits for you.
	Default it true, because it is very convenient from a development standpoint, but as say depending on situation, it can be operationally inconvenient it there is an issue.

	Lengthening the COMMIT INTERVAL will provide an upper bound in which you can ensure your record processing will be finish, but it could also create an large offset GAP, where the commits are lagging behind your processing positions.
	As long as there is a gap, there is some risk exposre to faliure, and the possible inconsistent state you mat be left with to clean up.

	Possible Duplication of records when reprocessing. 


Another property, is the strategy to use when a consumer starts to read from a new partition. The default is to read from the latest known commited offset. (also be set to earliest)
There is also a setting for none, which is basically asking Kafka to throw an expection to the consmer and let consumer decide what to do with it.



How and where offsets are stored in Kafka?
Kafka stores the commited offsets in a special topic called '__consumer_offsets', it has 50 partitions. 
It is the designated topic to sore all of the consumers offset throughout the entire Kafka cluster.

How does the commited offset values get produced into the topic?
ConsumerCoordinator is the responsible object for communicating to the cluster and ensuring the committed offsets are produced into the topic.
This means the consumer is also a producer of sorts.


Two modes of Offset Management, enable.auto.commit = true (Default)
To switch to manual mode, you simply set enable.auto.commit = false
When you do this, you will take full control of offset commits, ie full control of when you want Kafka to consider a record to be fully processed. 

The API for manual offset management consists of two methods:
	commitSync
	commitAsync



CommitSycn & CommitAync


CommitSycn:-
You would use commit sync method when you want the precise control over when to consider a record truly processed. 
This is common circumstances where higher consistency and message processing fidelity is required, where you wouldn't want to retrieve and process new records until you are sure the once you have currently processed are committed. 
Recommended that you call this method when the batch of consumer records in the for loop has been processed.
This method can be called up after every record processed, but this is over-kill the added latency.

Beacuse the call is synchronous, and will block the thread until it recieves a response from the cluster. 
If in case the response is an Exception, then we have to start the recovery.

The good news about CommitSycn is that it will automatically retries the commit until is succeeds or till unrecoverable error. 

retry.backoff.ms -> To control the retries interval (default 100 milisecond)

With this manual offset management mode, you may be trading throughput and preformance for control over the consistency.


CommitAync:-
To control when to considered your message truly processed.
The difference is due to the asynchronous nature of the call you may not know when the commit succeeded OR NOT.
Because of this commitAsync methods DO NOT automatically retries when a commit doesn't happen. 
Retrying without knowing whether the first commit succeeded or failed would lead to ordering issues and possible duplication of records. 
However there is a useful option to pass in, and that is a CALLBACK.

That CALLBACK will be triggered upon the commit response from the cluster.
With this CALLBACK you can determine the status of the commit and act accordingly.

Since, this is non-blocking option, the throughput and the preformance will going to be better as we don't have to wait for a response to continue processing. 

Woudl recommend to only use this option if you can reginster a callback and can handle the response accordingly, otherwise you could end up in a worse situation altogether.



The place where the offset management occurs is after the poll method has timeout and presented records for processing. Whether this is an auto commit operation hapenning behind the scene, or an explicit call to one of the commit API, the commit process will take a batch of records, determine their offsets and aks the ConsumerCoordinator to commit them to Kafka cluster with the Consumer Network Client, which it does immediately.

When the offsets have been successfully commited, the ConsumerCoordinatorupdate the subscription list object accordingly, so the Fetcher can alwas know waht offsets have been commited and wat next records it should be retrieving. 


-> Kafka's API for complete offset management provided for:-
	Consistency Control (Fine grained control)
		When a message is processed.
	Atomocty - Being able to treat the steps of message consumption and processed as a single atomic operation. (For Highly Consistent system)



 

It isn't realistinc for a single consumer application (which is single threaded), to take on the entire burder of message processing from pottentially many topics and many partitions.

Scale of the consumer applications -> Multiple Consumers, but they need to work in concert with one another.

Consumer Groups:-
Kafka's solution to Consumer-side scale-out
If a collection of individual independent consumer process working together as a team.
The only thing required to join a consumer to Consumer-Group is the GROUP-ID (group.id setting, before starting the consumer)

When the consumer is a part of the Consumer-Group, the taks of processing the messages for the entire topic is distributed as evenly as possible amongst the number of consumers.

-> HIgh level or overall throughput with this parallelism.
-> Redudancy, as faliure of a single consumber is automatically handeled and balanced by Kafka.



A Consumer-Group is formed when the consumers with a common group-Id invoke the subscribe method and pass in a common TOPIC LIST.
Behind the scenes, a designated BROKER is elected to serve as the GROUP CO-ORDINATOR, whose job is to monitor and maintain the Consumer-Group's membership.
In addition, the group co-ordinator works with the cluster co-ordinator and Zookeeper to assing and monitor specific PARTITIONS within a topic to individual consumers within the consumer group.


Form the second, the consumer group is formed, each consumer is sending a regular heartbeats at an interval defined in heartbeat.interval.ms property.

The group co-ordinator relies on this heartbeat to determine whether the individual consumer is alive and is able to participate in the group.

The session.timeout.ms setting is the amount of toal time the group co-ordinator will wait after not receiving any heart-beat before it considere the consumer to be failed and take corrective action.

The group co-ordinator's main priority is to ensure that the puspose of the group is being met, and that is to share the load of a topic's messages amongst all its group members.

If there is a consumer that isn't avaibale to share that load, the group co-ordinator will remove that consumer and reassing its partitions to another consumer in the group. This is called the consumer rebalance.

If there isn't any additional consumers in the Consumer-Group, then the first consumer in the graoup will get the assingnment, and in this end up taking on twice the load to compensate the failed consumer.

Now, the first consumer has to figure out where the failed consumer left off and catch up, hopefully without processing duplica records. 
This is why the offset management can make or break the Kafka consumers because if it is not handeled correctly, the ability for the consumer group to failover and rebalance can be compromised.

Consider the case when the failed consumer processed the message, but failed to commit the messages before it failed. The first consumer will likely reprocess the messages because it had no idea what record were actually commited or not.
If an when a new consumer joins the group, another rebalance will occur and the same rebalance protocol will be followed.

It is not just a consumer coming in and out of the consumer group that cause a rebalance, it is alos the addition of new partition.






What happed when a new consumer will be assigned a partition that is previously assigned to another consumer?

When a new consumer is assigned a partition, say partition-0, it needs to what offset is should start from, because it does not have the correct position for this particular partition.

Fortunately, the consumer subscription state object has cached the last committed offset from the previous consumer, and can instruct the new consumer that on its first POLL on the new partition, that is need to start form a particular offset, since the last commit offset is one less than that.

This behaviour of determining where the new consumer should reset its offset to is configured in auto offset reset setting.

Since the default is 'latest', the new consumer will start reading from the latest commited known committed possition. Ofcourse, this assumes that the committed offset is accuractly nad completely commited when the previous consumer was rebalanced.

If the previous consumer was in the middle of processing records, and didn't have the chance to commit its offset, when the rebalance happen, then there could be a chance that when the new consumer picks up, it could be reading from already processed record thus creacting duplicates. 


Groups Co-ordinator Duties:-
	-- Primary purpose is to make sure each consumer in the Consumer-Group is sharing the partition load across the group.
	-- Whenever it can, it will assing one partition to one consumer, if there is equal no of partitions and consumers.
	-- If the number of consumers are more than the no of available partitions, then they will be idle, creating an consumer over provisioning scenario that the Group Co-ordinator cannot change unless partitions become available. When partition does become available, the Group Co-ordinator will initiate a rebalancing protocol by enganing each consumer co-ordinator in the impacted consumers to start the process of rebalancing, so that the newly added partition can be assigned to a consumer.

	-- The rebalancing protocol is also initiated during consumer faliure.



Demo: Consumer Groups




Some Advanced Configuration and Advance Topics:-

fetch.min.bytes -> Set the minimum number of bytes that must be returned from the poll
max.fetch.wait.ms -> It the amount of timw to wait, if there isn't enough data to meet the threshold set by 	the fetch.min.bytes

max.partition.fetch.bytes -> To ensure each poll isn't retrieving more data htan your processing loop can 		handle safely.

max.poll.records -> Maximum number of records allowed per poll



There are additional methods and API's to take complete control on the consumers behavious.
We can specify how we want the consumer to read a partitions messages by using the consumer position control API
	seek() -> Allows to specify the specific  offset you want to read in a given topic and partition.
	seekToBeginning() -> Start from the beginning of the specific topic and partition.
	seekToEnd()


Control the Flow of messages:-
	pause()
	resume()
		-- Can be set on topic and partitions to pause and resume.

Rebalance Listeners
These listeners will notify when a rebalance event occurs, so we can handle the offset ourself. 





Kafka Ecosystem and Its Future: _________________

Kafka is generally regarders as the primary solution for connectin sisparate sources of data.
With its flexible clent API's, it is possible to write data connectors and syncs for practically any data source. 
Kafka is becoming the defacto options for building data supply chains and pipelines that can displace lond-standing, expensive and fragile ETL environments.

Also Kafka fits really well with other Big-Data technologies like Hadoop, Spark amongst others, because of its ability to integrave, move and store data at massive scale.


Kafka's challenges in Data Governance and Evolution
The challenge with Kafka is the lack of some common means of cataloging, registering and reconciling the disparate message specifications and compatibility mapping between the serializing producer and the de-serializing consumers. 

Kafka Schema Registry:-
	One of the more universal data serialization formats out there today is Apache AVRO
	It was created to address the challenges with disparate data formats and serialization schemes that make integration and inter-operatibility difficult.
	It is a self describing version format that is broad industry adoption.

	With Avro, producers can serialize their messages in an AVRO versioned and self-describing format, and expect them to be deserialized seamlessly by the consumers.

	The schema used by both producers and consumers can be registered and version managed centrally within the Kafka cluster environment, allowinf for easy, restful, service based discovery and version compatibility reconciliation. 



Challenges with Consistency and Productivity:

-- Kafka Connect and Connector Hub


Streaming Data Capability in Kafka



0.10 release of Apache Kafka.